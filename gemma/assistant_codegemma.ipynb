{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7utIJyMQlm_",
        "outputId": "c3dfc099-a6b6-4e67-b53b-b61773ff65ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Apr  9 14:57:30 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Author: Jimmy Liao <sjliao@gmail.com>\n",
        "# Please use Colab with T4, TPU runtime\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1-HmO07RKVu",
        "outputId": "02989902-c01b-4a11-c881-6d0bb970139a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Downloading ollama...\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GfN5onsQ_nz",
        "outputId": "be9249fa-b27b-4b9d-a489-496e08e316cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['ollama', 'serve']>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import subprocess\n",
        "subprocess.Popen([\"ollama\", \"serve\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOFsS0eOREXB",
        "outputId": "2bb448a5-9cc5-4c1b-b3b2-237be623796a"
      },
      "outputs": [],
      "source": [
        "!ollama pull codegemma:7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd7B3pD3TXUS",
        "outputId": "7761f2e9-9408-4054-c236-cd19615f18fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME        \tID          \tSIZE  \tMODIFIED               \n",
            "codegemma:7b\tca966f70c13f\t5.0 GB\tLess than a second ago\t\n"
          ]
        }
      ],
      "source": [
        "!ollama list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "i4Oy0FWiSHXP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "model_name = \"codegemma:7b\"\n",
        "\n",
        "url=\"http://localhost:11434/api/generate\"\n",
        "\n",
        "headers ={\n",
        "    \"Content-Type\":\"application/json\"\n",
        "}\n",
        "\n",
        "history=[]\n",
        "\n",
        "def generate_response(prompt):\n",
        "    history.append(prompt)\n",
        "    final_prompt = \"\\n\".join(history)\n",
        "\n",
        "    data = {\n",
        "        \"model\":model_name,\n",
        "        \"prompt\":final_prompt,\n",
        "        \"stream\":False\n",
        "    }\n",
        "\n",
        "    response = requests.post(url,headers=headers, data=json.dumps(data))\n",
        "\n",
        "    if response.status_code ==200:\n",
        "        response = response.text\n",
        "        data=json.loads(response)\n",
        "        actual_response = data['response']\n",
        "        return actual_response\n",
        "    else:\n",
        "        print(\"error\",response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "47xkszoRSWIl",
        "outputId": "08cca6be-2b02-4e18-f96b-3cef11c1ca96"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'```python\\ndef fibonacci(n):\\n  \"\"\"\\n  This function takes an integer n and returns the nth fibonacci number.\\n  The fibonacci sequence is defined as follows:\\n    - The first two numbers are 0 and 1.\\n    - Each subsequent number is the sum of the two previous numbers.\\n  \"\"\"\\n  if n <= 0:\\n    return 0\\n  elif n == 1:\\n    return 1\\n  else:\\n    # Use dynamic programming to avoid redundant computations.\\n    fib_sequence = [0, 1]\\n    for i in range(2, n + 1):\\n      fib_sequence.append(fib_sequence[i - 1] + fib_sequence[i - 2])\\n    return fib_sequence[n]\\n\\n# Example usage:\\nnth_fibonacci = fibonacci(10)\\nprint(nth_fibonacci)  # Output: 55\\n```'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt='You are an expert programmer that writes simple, concise code and explanations. Write a python function to generate the nth fibonacci number.'\n",
        "\n",
        "resp = generate_response(prompt)\n",
        "\n",
        "resp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRZLZoDWTKrj",
        "outputId": "b3917f83-4ff2-4468-c3c6-4d30ea00e2ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('```python\\n'\n",
            " 'def fibonacci(n):\\n'\n",
            " '  \"\"\"\\n'\n",
            " '  This function takes an integer n '\n",
            " 'and returns the nth fibonacci '\n",
            " 'number.\\n'\n",
            " '  The fibonacci sequence is defined '\n",
            " 'as follows:\\n'\n",
            " '    - The first two numbers are 0 '\n",
            " 'and 1.\\n'\n",
            " '    - Each subsequent number is the '\n",
            " 'sum of the two previous numbers.\\n'\n",
            " '  \"\"\"\\n'\n",
            " '  if n <= 0:\\n'\n",
            " '    return 0\\n'\n",
            " '  elif n == 1:\\n'\n",
            " '    return 1\\n'\n",
            " '  else:\\n'\n",
            " '    # Use dynamic programming to '\n",
            " 'avoid redundant computations.\\n'\n",
            " '    fib_sequence = [0, 1]\\n'\n",
            " '    for i in range(2, n + 1):\\n'\n",
            " '      '\n",
            " 'fib_sequence.append(fib_sequence[i - '\n",
            " '1] + fib_sequence[i - 2])\\n'\n",
            " '    return fib_sequence[n]\\n'\n",
            " '\\n'\n",
            " '# Example usage:\\n'\n",
            " 'nth_fibonacci = fibonacci(10)\\n'\n",
            " 'print(nth_fibonacci)  # Output: 55\\n'\n",
            " '```')\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(resp, width=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ51SvRVT_Ao"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
