{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Origin: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuhjNPTpju5n"
      },
      "source": [
        "# Gemini API: Embeddings Quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUsgeyPu6ogK"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddZb9-z46mM5"
      },
      "source": [
        "The Gemini API generates state-of-the-art text embeddings. An embedding is a list of floating point numbers that represent the meaning of a word, sentence, or paragraph. You can use embeddings in many downstream applications like document search.\n",
        "\n",
        "This notebook provides quick code examples that show you how to get started generating embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YD6urJjWGVDf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yBapI259C99C"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jimmy.liao/.pyenv/versions/3.10.13/envs/lab_gemini/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJriBaWmkL6Z"
      },
      "source": [
        "## Configure your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see  [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Zey3UiYGDDzU"
      },
      "outputs": [],
      "source": [
        "# from google.colab import userdata\n",
        "# GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "GOOGLE_API_KEY = \"AIzaS-----\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGpQ8Eg0kNXW"
      },
      "source": [
        "## Embed content\n",
        "\n",
        "Call the `embed_content` method with the `models/text-embedding-004` model to generate text embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J76TNa3QDwCc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.013168523, -0.008711934, -0.046782676, 0.000699 ... TRIMMED]\n"
          ]
        }
      ],
      "source": [
        "text = \"Hello world\"\n",
        "result = genai.embed_content(model=\"models/text-embedding-004\", content=text)\n",
        "\n",
        "# Print just a part of the embedding to keep the output manageable\n",
        "print(str(result['embedding'])[:50], '... TRIMMED]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rU6XX33547Ll"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "768\n"
          ]
        }
      ],
      "source": [
        "print(len(result['embedding'])) # The embeddings have 768 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.003930476, 0.053186826, -0.014137892, 0.0326257 ... TRIMMED]\n"
          ]
        }
      ],
      "source": [
        "# Try Chinse text\n",
        "text = \"你好，我是吉米廖\"\n",
        "result = genai.embed_content(model=\"models/text-embedding-004\", content=text)\n",
        "\n",
        "# Print just a part of the embedding to keep the output manageable\n",
        "print(str(result['embedding'])[:50], '... TRIMMED]')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.010790566, 0.03776539, 0.0071558105, 0.0184076 ... TRIMMED]\n",
            "768\n"
          ]
        }
      ],
      "source": [
        "# Try another Chinse text\n",
        "text = \"台灣是一個美麗的島嶼\"\n",
        "result = genai.embed_content(model=\"models/text-embedding-004\", content=text)\n",
        "\n",
        "# Print just a part of the embedding to keep the output manageable\n",
        "print(str(result['embedding'])[:50], '... TRIMMED]')\n",
        "print(len(result['embedding'])) # The embeddings have 768 dimensions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.037555765, -0.05598569, -0.029523352, -0.005206 ... TRIMMED]\n",
            "768\n"
          ]
        }
      ],
      "source": [
        "# Use embedding-001\n",
        "text = \"你好，我是吉米廖\"\n",
        "result = genai.embed_content(model=\"models/embedding-001\", content=text)\n",
        "\n",
        "\n",
        "# Print just a part of the embedding to keep the output manageable\n",
        "print(str(result['embedding'])[:50], '... TRIMMED]')\n",
        "print(len(result['embedding'])) # The embeddings have 512 dimensions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0427908, -0.064218625, -0.023080552, -0.0044756 ... TRIMMED]\n",
            "768\n"
          ]
        }
      ],
      "source": [
        "# Use embedding-001\n",
        "text = \"台灣是一個美麗的島嶼\"\n",
        "result = genai.embed_content(model=\"models/embedding-001\", content=text)\n",
        "\n",
        "\n",
        "# Print just a part of the embedding to keep the output manageable\n",
        "print(str(result['embedding'])[:50], '... TRIMMED]')\n",
        "print(len(result['embedding'])) # The embeddings have 512 dimensions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0427908, -0.064218625, -0.023080552, -0.0044756 ... TRIMMED]\n",
            "768\n"
          ]
        }
      ],
      "source": [
        "# Use embedding-001\n",
        "text = \"今天天氣很好\"\n",
        "result = genai.embed_content(model=\"models/embedding-001\", content=text)\n",
        "\n",
        "\n",
        "# Print just a part of the embedding to keep the output manageable\n",
        "print(str(result['embedding'])[:50], '... TRIMMED]')\n",
        "print(len(result['embedding'])) # The embeddings have 512 dimensions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0427908, -0.064218625, -0.023080552, -0.0044756 ... TRIMMED]\n",
            "768\n"
          ]
        }
      ],
      "source": [
        "# Use embedding-001\n",
        "text = \"我很開心\"\n",
        "result = genai.embed_content(model=\"models/embedding-001\", content=text)\n",
        "\n",
        "\n",
        "# Print just a part of the embedding to keep the output manageable\n",
        "print(str(result['embedding'])[:50], '... TRIMMED]')\n",
        "print(len(result['embedding'])) # The embeddings have 512 dimensions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "  return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "ename": "NotFound",
          "evalue": "404 models/text-multilingual-embedding-preview-0409 is not found for API version v1beta, or is not supported for embedContent. Call ListModels to see the list of available models and their supported methods.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/lab_gemini/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:79\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/lab_gemini/lib/python3.10/site-packages/grpc/_channel.py:1176\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1170\u001b[0m (\n\u001b[1;32m   1171\u001b[0m     state,\n\u001b[1;32m   1172\u001b[0m     call,\n\u001b[1;32m   1173\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1174\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1175\u001b[0m )\n\u001b[0;32m-> 1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/lab_gemini/lib/python3.10/site-packages/grpc/_channel.py:1005\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"models/text-multilingual-embedding-preview-0409 is not found for API version v1beta, or is not supported for embedContent. Call ListModels to see the list of available models and their supported methods.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.43.10:443 {grpc_message:\"models/text-multilingual-embedding-preview-0409 is not found for API version v1beta, or is not supported for embedContent. Call ListModels to see the list of available models and their supported methods.\", grpc_status:5, created_time:\"2024-05-28T21:09:28.890503+08:00\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m text1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m今天天氣很好\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m text2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m我很開心\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m result1 \u001b[38;5;241m=\u001b[39m \u001b[43mgenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# model=\"models/embedding-001\",\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/text-multilingual-embedding-preview-0409\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msimilarity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m result2 \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39membed_content(\n\u001b[1;32m     11\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/text-multilingual-embedding-preview-0409\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     content\u001b[38;5;241m=\u001b[39mtext2,\n\u001b[1;32m     13\u001b[0m     task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(result1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m])[:\u001b[38;5;241m50\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m... TRIMMED]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/lab_gemini/lib/python3.10/site-packages/google/generativeai/embedding.py:210\u001b[0m, in \u001b[0;36membed_content\u001b[0;34m(model, content, task_type, title, output_dimensionality, client, request_options)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     embedding_request \u001b[38;5;241m=\u001b[39m glm\u001b[38;5;241m.\u001b[39mEmbedContentRequest(\n\u001b[1;32m    204\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    205\u001b[0m         content\u001b[38;5;241m=\u001b[39mcontent_types\u001b[38;5;241m.\u001b[39mto_content(content),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m         output_dimensionality\u001b[38;5;241m=\u001b[39moutput_dimensionality,\n\u001b[1;32m    209\u001b[0m     )\n\u001b[0;32m--> 210\u001b[0m     embedding_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     embedding_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(embedding_response)\u001b[38;5;241m.\u001b[39mto_dict(embedding_response)\n\u001b[1;32m    215\u001b[0m     embedding_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m embedding_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/lab_gemini/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:1224\u001b[0m, in \u001b[0;36mGenerativeServiceClient.embed_content\u001b[0;34m(self, request, model, content, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1224\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/lab_gemini/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/lab_gemini/lib/python3.10/site-packages/google/api_core/retry.py:372\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    369\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    371\u001b[0m )\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/lab_gemini/lib/python3.10/site-packages/google/api_core/retry.py:207\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    209\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/lab_gemini/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/lab_gemini/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:81\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[0;31mNotFound\u001b[0m: 404 models/text-multilingual-embedding-preview-0409 is not found for API version v1beta, or is not supported for embedContent. Call ListModels to see the list of available models and their supported methods."
          ]
        }
      ],
      "source": [
        "# Compare two embeddings from two texts\n",
        "# text1 = \"今天天氣很好\"\n",
        "# text2 = \"我很開心\"\n",
        "text1 = \"台灣是一個美麗的島嶼\"\n",
        "text2 = \"我很開心\"\n",
        "\n",
        "result1 = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=text1,\n",
        "    task_type='similarity')\n",
        "result2 = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=text2,\n",
        "    task_type=\"similarity\")\n",
        "\n",
        "print(str(result1['embedding'])[:50], '... TRIMMED]')\n",
        "print(str(result2['embedding'])[:50], '... TRIMMED]')\n",
        "\n",
        "# Compute the cosine similarity between the two embeddings\n",
        "# similarity = genai.cosine_similarity(result1['embedding'], result2['embedding'])\n",
        "# print(similarity)\n",
        "# similarity = cosine_similarity(result1['embedding'], result2['embedding'])\n",
        "# print(similarity)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUKqxF9yQuZl"
      },
      "source": [
        "## Batch embed content\n",
        "\n",
        "You can embed a list of multiple prompts with one API call for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Hzz-7Heuf4tV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.010632277, 0.019375855, 0.0209652, 0.000770642 ... TRIMMED]\n",
            "[0.018467998, 0.0054281196, -0.017658804, 0.013859 ... TRIMMED]\n",
            "[0.05808907, 0.020941721, -0.108728774, -0.0403925 ... TRIMMED]\n"
          ]
        }
      ],
      "source": [
        "result = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=[\n",
        "      'What is the meaning of life?',\n",
        "      'How much wood would a woodchuck chuck?',\n",
        "      'How does the brain work?'])\n",
        "\n",
        "for embedding in result['embedding']:\n",
        "  print(str(embedding)[:50], '... TRIMMED]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0r0dt958QQg"
      },
      "source": [
        "## Truncating embeddings\n",
        "\n",
        "The `text-embedding-004` model also supports lower embedding dimensions. Specify `output_dimensionality` to truncate the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bX_AjfMx8PvV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(768, 10)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Not truncated\n",
        "result1 = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=\"Hello world\")\n",
        "\n",
        "\n",
        "# Truncated\n",
        "result2 = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=\"Hello world\",\n",
        "    output_dimensionality=10)\n",
        "\n",
        "\n",
        "(len(result1['embedding']), len(result2['embedding']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSKcLGIpo8yc"
      },
      "source": [
        "## Specify `task_type`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz0zq1_shk98"
      },
      "source": [
        "Let's look at all the parameters the `embed_content` method takes. There are five:\n",
        "\n",
        "* `model`: Required. Must be `models/text-embedding-004` or `models/embedding-001`.\n",
        "* `content`: Required. The content that you would like to embed.\n",
        "*`task_type`: Optional. The task type for which the embeddings will be used.\n",
        "* `title`: Optional. You should only set this parameter if your task type is `retrieval_document` (or `document`).\n",
        "* `output_dimensionality`: Optional. Reduced dimension for the output embedding. If set, excessive values in the output embedding are truncated from the end. This is supported by `models/text-embedding-004`, but cannot be specified in `models/embedding-001`.\n",
        "\n",
        "`task_type` is an optional parameter that provides a hint to the API about how you intend to use the embeddings in your application.\n",
        "\n",
        "The following task_type parameters are accepted:\n",
        "\n",
        "* `unspecified`: If you do not set the value, it will default to `retrieval_query`.\n",
        "* `retrieval_query` (or `query`): The given text is a query in a search/retrieval setting.\n",
        "* `retrieval_document` (or `document`): The given text is a document from a corpus being searched. Optionally, also set the `title` parameter with the title of the document.\n",
        "* `semantic_similarity` (or `similarity`): The given text will be used for  Semantic Textual Similarity (STS).\n",
        "* `classification`: The given text will be classified.\n",
        "* `clustering`: The embeddings will be used for clustering.\n",
        "* `question_answering`: The given text will be used for question answering.\n",
        "* `fact_verification`: The given text will be used for fact verification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LFjMapMV91es"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.013168523, -0.008711934, -0.046782676, 0.000699 ... TRIMMED]\n",
            "[0.023399517, -0.00854715, -0.052534223, -0.012143 ... TRIMMED]\n"
          ]
        }
      ],
      "source": [
        "# Notice the API returns different embeddings depending on `task_type`\n",
        "result1 = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=\"Hello world\")\n",
        "\n",
        "result2 = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=\"Hello world\",\n",
        "    task_type=\"document\")\n",
        "\n",
        "print(str(result1['embedding'])[:50], '... TRIMMED]')\n",
        "print(str(result2['embedding'])[:50], '... TRIMMED]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpBm7GIdbkdK"
      },
      "source": [
        "## Learning more\n",
        "\n",
        "Check out these examples in the Cookbook to learn more about what you can do with embeddings:\n",
        "\n",
        "* [Search Reranking](https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb): Use embeddings from the Gemini API to rerank search results from Wikipedia.\n",
        "\n",
        "* [Anomaly detection with embeddings](https://github.com/google-gemini/cookbook/blob/main/examples/Anomaly_detection_with_embeddings.ipynb): Use embeddings from the Gemini API to detect potential outliers in your dataset.\n",
        "\n",
        "* [Train a text classifier](https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb): Use embeddings from the Gemini API to train a model that can classify different types of newsgroup posts based on the topic.\n",
        "\n",
        "* Embeddings have many applications in Vector Databases, too. Check out this [example with Chroma DB](https://github.com/google/generative-ai-docs/blob/main/examples/gemini/python/vectordb_with_chroma/vectordb_with_chroma.ipynb).\n",
        "\n",
        "You can learn more about embeddings in general on ai.google.dev in the [embeddings guide](https://ai.google.dev/docs/embeddings_guide)\n",
        "\n",
        "* You can find additional code examples with the Python SDK [here](https://ai.google.dev/tutorials/python_quickstart#use_embeddings).\n",
        "\n",
        "* You can also find more details in the API Reference for [embedContent](https://ai.google.dev/api/rest/v1/models/embedContent) and [batchEmbedContents](https://ai.google.dev/api/rest/v1/models/batchEmbedContents)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Embeddings.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
