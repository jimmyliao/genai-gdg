{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijGzTHJJUCPY",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Credit by https://www.pragnakalp.com/openai-function-calling-with-external-api-examples/\n",
        "# Modified and Optimized by Jimmy Liao <sjliao@gmail.com>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEqbX8OhE8y9"
      },
      "source": [
        "# Function Calling with the Vertex AI Gemini API & Python SDK\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/jimmyliao/genai-gdg/blob/main/gemini/function-calling/function_calling_rest.ipynb\" target=\"_blank\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/jimmyliao/genai-gdg/blob/main/gemini/function-calling/function_calling_rest.ipynb\" target=\"_blank\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htKVhbvwIzk5"
      },
      "source": [
        "|Author(s) | Notes |\n",
        "|-|-|\n",
        "| [Jimmy Liao](https://github.com/jimmyliao)  | Init |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkHPv2myT2cx"
      },
      "source": [
        "## Overview\n",
        "\n",
        "### Gemini\n",
        "\n",
        "Gemini is a family of generative AI models developed by Google DeepMind that is designed for multimodal use cases.\n",
        "\n",
        "### Calling functions from Gemini\n",
        "\n",
        "[Function calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling) lets developers create a description of a function in their code, then pass that description to a language model in a request. The response from the model includes the name of a function that matches the description and the arguments to call it with.\n",
        "\n",
        "Function calling is similar to [Vertex AI Extensions](https://cloud.google.com/vertex-ai/docs/generative-ai/extensions/overview) in that they both generate information about functions. The difference between them is that function calling returns JSON data with the name of a function and the arguments to use in your code, whereas Vertex AI Extensions returns the function and calls it for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrkcqHrrwMAo"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "You will create the application that uses the Gemini function calling feature to call external APIs. These APIs will provide the current stock price of a company listed in the United States from user input. Also the application will provide the utility to show the current currency exchange rate between two countries.\n",
        "\n",
        "To get the current stockt price, you will use the [Alpha Vantage API](https://www.alphavantage.co/documentation/) and Finnhub API.\n",
        "\n",
        "\n",
        "You will complete the following tasks:\n",
        "- Setup the environment\n",
        "- Create a function-calling request\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9nEPojogw-g"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "- Vertex AI\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11Gu7qNgx1p"
      },
      "source": [
        "## Getting Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip3 install -q --upgrade --user google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart current runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRvKdaPDTznN",
        "outputId": "ebb9fd14-727c-4b2f-d052-f41776d677ab",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "import time\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Define Google Cloud project information and initialize Vertex AI\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define project information\n",
        "PROJECT_ID = \"<gen-lang-client-xxx>\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHfaVS66_01"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lslYAvw37JGQ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from vertexai.generative_models import (\n",
        "    Content,\n",
        "    FunctionDeclaration,\n",
        "    GenerativeModel,\n",
        "    Part,\n",
        "    Tool,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcrPT5gs5IcH"
      },
      "outputs": [],
      "source": [
        "### Install Finnhub\n",
        "!pip install -q finnhub-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqnmSV7b5IcH"
      },
      "outputs": [],
      "source": [
        "# Import libaries\n",
        "import json\n",
        "import requests\n",
        "import finnhub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boZn6B8s5IcI"
      },
      "outputs": [],
      "source": [
        "# Step 1.1. Test Chat Prompts with SDK\n",
        "model = GenerativeModel(\"gemini-1.0-pro\")\n",
        "\n",
        "chat = model.start_chat()\n",
        "\n",
        "prompt = \"\"\"My name is Jimmy Liao. You are my personal assistant. My favorite movies are Dune: part 2.\n",
        "\n",
        "Suggest another movie I might like.\n",
        "\"\"\"\n",
        "\n",
        "responses = chat.send_message(prompt, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtQjG_U25IcI"
      },
      "outputs": [],
      "source": [
        "# Step 1.2. Test Chat Promopts with API\n",
        "# curl https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=$API_KEY \\\n",
        "#     -H 'Content-Type: application/json' \\\n",
        "#     -X POST \\\n",
        "#     -d '{\n",
        "\n",
        "prompt_text=\"My name is Jimmy Liao. You are my personal assistant. My favorite movies are Dune: part 2. Suggest another movie I might like.\"\n",
        "API_KEY = \"<gen>\"\n",
        "\n",
        "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={API_KEY}\"\n",
        "data = {\n",
        "    \"contents\": [{\n",
        "        \"parts\": [\n",
        "            \"text\": prompt_text\n",
        "        ]\n",
        "    }]\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=data)\n",
        "print(response.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80VKRiyt5IcI"
      },
      "outputs": [],
      "source": [
        "# Step 2. Create Utility to facilitate the Chat Completion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-CwF8yrIzk8"
      },
      "source": [
        "## Code Examples\n",
        "\n",
        "### Why function calling?\n",
        "\n",
        "When working with a generative text model, it can be difficult to coerce the LLM to give consistent responses in a structured format such as JSON. Function calling makes it easy to work with LLMs via prompts and unstructured inputs, and have the LLM return a structured response that can be used to call an external function.\n",
        "\n",
        "You can think of function calling as a way to get structured output from user prompts and function definitions, use that structured output to make an API request to an external system, then return the function response to the LLM to generate a response to the user. In other words, function calling in Gemini extracts structured parameters from unstructured text or messages from users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4437b7608c8e"
      },
      "source": [
        "### Use the Gemini 1.0 Pro model\n",
        "\n",
        "The Gemini 1.0 Pro (`gemini-1.0-pro`) model is designed to handle natural language tasks, multiturn text and code chat, and code generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2998506fe6d1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\"gemini-1.0-pro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiQgsuqMIzk8"
      },
      "source": [
        "### Simple function calling example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVJB49fqIzk8"
      },
      "source": [
        "To begin, you'll use function calling to set up a weather API request for users to obtain the current conditions in a given location. Function parameters are specified as a Python dictionary in accordance with the [OpenAPI JSON schema format](https://spec.openapis.org/oas/v3.0.3#schemawr).\n",
        "\n",
        "Consider an example weather API function that takes in an argument for the user's location, as in:\n",
        "\n",
        "```python\n",
        "def get_current_weather(location):\n",
        "    ...\n",
        "```\n",
        "\n",
        "You'll start by specifying a function declaration and parameters needed to make a request our example weather API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r02tRUxpIzk8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "get_current_weather_func = FunctionDeclaration(\n",
        "    name=\"get_current_weather\",\n",
        "    description=\"Get the current weather in a given location\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"Location\"}},\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQPSTAV8Izk9"
      },
      "source": [
        "You can then define a tool for the LLM to call that includes the `get_current_weather_func`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVfDn0dQIzk9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "weather_tool = Tool(\n",
        "    function_declarations=[get_current_weather_func],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-Z95UeSIzk9"
      },
      "source": [
        "You can then instruct the model to generate content, include the `tool` that you just created, to generate a response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6chdNkPFIzk9",
        "outputId": "234649e7-5d95-4794-f514-efb8e679d0c1",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "candidates {\n",
              "  content {\n",
              "    role: \"model\"\n",
              "    parts {\n",
              "      function_call {\n",
              "        name: \"get_current_weather\"\n",
              "        args {\n",
              "          fields {\n",
              "            key: \"location\"\n",
              "            value {\n",
              "              string_value: \"Boston\"\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  finish_reason: STOP\n",
              "  safety_ratings {\n",
              "    category: HARM_CATEGORY_HATE_SPEECH\n",
              "    probability: NEGLIGIBLE\n",
              "    probability_score: 0.06030764430761337\n",
              "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
              "    severity_score: 0.07709969580173492\n",
              "  }\n",
              "  safety_ratings {\n",
              "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "    probability: NEGLIGIBLE\n",
              "    probability_score: 0.16681109368801117\n",
              "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
              "    severity_score: 0.1563623547554016\n",
              "  }\n",
              "  safety_ratings {\n",
              "    category: HARM_CATEGORY_HARASSMENT\n",
              "    probability: NEGLIGIBLE\n",
              "    probability_score: 0.09318171441555023\n",
              "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
              "    severity_score: 0.07654563337564468\n",
              "  }\n",
              "  safety_ratings {\n",
              "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "    probability: NEGLIGIBLE\n",
              "    probability_score: 0.04146227240562439\n",
              "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
              "    severity_score: 0.06941547244787216\n",
              "  }\n",
              "}\n",
              "usage_metadata {\n",
              "  prompt_token_count: 23\n",
              "  candidates_token_count: 7\n",
              "  total_token_count: 30\n",
              "}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"What is the weather like in Boston?\"\n",
        "\n",
        "response = model.generate_content(\n",
        "    prompt,\n",
        "    generation_config={\"temperature\": 0},\n",
        "    tools=[weather_tool],\n",
        ")\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2nLAV0zIzk9"
      },
      "source": [
        "You can inspect the function call portion of the response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXt4Zjz5Izk9",
        "outputId": "7f77e861-bbe4-4221-d6ef-400c530c0a14",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "name: \"get_current_weather\"\n",
              "args {\n",
              "  fields {\n",
              "    key: \"location\"\n",
              "    value {\n",
              "      string_value: \"Boston\"\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.candidates[0].content.parts[0].function_call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB-vxjyeIzk9"
      },
      "source": [
        "The response includes a function signature that can be used to call the weather API. At this point, you have everything that you need to form a request body and make an API call to an external system. Nice work!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWklTR2fIzk9"
      },
      "source": [
        "### Complex function calling example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUF1nsx9Izk9"
      },
      "source": [
        "In this example, you'll generate a function call that has a more complex structure. You'll use the function response to make an API call that converts an address to latitude and longitude coordinates.\n",
        "\n",
        "Start by defining a function declaration within a tool:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKrICInkIzk9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "get_location = FunctionDeclaration(\n",
        "    name=\"get_location\",\n",
        "    description=\"Get latitude and longitude for a given location\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"poi\": {\"type\": \"string\", \"description\": \"Point of interest\"},\n",
        "            \"street\": {\"type\": \"string\", \"description\": \"Street name\"},\n",
        "            \"city\": {\"type\": \"string\", \"description\": \"City name\"},\n",
        "            \"county\": {\"type\": \"string\", \"description\": \"County name\"},\n",
        "            \"state\": {\"type\": \"string\", \"description\": \"State name\"},\n",
        "            \"country\": {\"type\": \"string\", \"description\": \"Country name\"},\n",
        "            \"postal_code\": {\"type\": \"string\", \"description\": \"Postal code\"},\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "location_tool = Tool(\n",
        "    function_declarations=[get_location],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8hy21jDIzk-"
      },
      "source": [
        "Now you can call the model to generate a response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKRNMjEVIzk-",
        "outputId": "cb870b86-cdb5-44d1-ad2a-61edfdabcb11",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "function_call {\n",
              "  name: \"get_location\"\n",
              "  args {\n",
              "    fields {\n",
              "      key: \"city\"\n",
              "      value {\n",
              "        string_value: \"Mountain View\"\n",
              "      }\n",
              "    }\n",
              "    fields {\n",
              "      key: \"country\"\n",
              "      value {\n",
              "        string_value: \"US\"\n",
              "      }\n",
              "    }\n",
              "    fields {\n",
              "      key: \"postal_code\"\n",
              "      value {\n",
              "        string_value: \"94043\"\n",
              "      }\n",
              "    }\n",
              "    fields {\n",
              "      key: \"state\"\n",
              "      value {\n",
              "        string_value: \"CA\"\n",
              "      }\n",
              "    }\n",
              "    fields {\n",
              "      key: \"street\"\n",
              "      value {\n",
              "        string_value: \"1600 Amphitheatre Pkwy\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "I want to get the lat/lon coordinates for the following address:\n",
        "1600 Amphitheatre Pkwy, Mountain View, CA 94043, US\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(\n",
        "    prompt,\n",
        "    generation_config={\"temperature\": 0},\n",
        "    tools=[location_tool],\n",
        ")\n",
        "response.candidates[0].content.parts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuCXg2aNIzk-"
      },
      "source": [
        "You can now extract the results from the function response and make an API call:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4W7NWJ-Izk-",
        "outputId": "c845000f-1e1a-4d80-d937-f1eab47394ad",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'place_id': 377680635,\n",
              "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright',\n",
              "  'osm_type': 'node',\n",
              "  'osm_id': 2192620021,\n",
              "  'lat': '37.4217636',\n",
              "  'lon': '-122.084614',\n",
              "  'category': 'office',\n",
              "  'type': 'it',\n",
              "  'place_rank': 30,\n",
              "  'importance': 0.6949356759210291,\n",
              "  'addresstype': 'office',\n",
              "  'name': 'Google Headquarters',\n",
              "  'display_name': 'Google Headquarters, 1600, Amphitheatre Parkway, Mountain View, Santa Clara County, California, 94043, United States',\n",
              "  'boundingbox': ['37.4217136', '37.4218136', '-122.0846640', '-122.0845640']}]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = response.candidates[0].content.parts[0].function_call.args\n",
        "\n",
        "agentheader={'User-Agent': 'PostmanRuntime/7.28.4'}\n",
        "\n",
        "url = \"https://nominatim.openstreetmap.org/search?\"\n",
        "for i in x:\n",
        "    # url += '{}=\"{}\"&'.format(i, x[i])\n",
        "    url += '{}={}&'.format(i, x[i].replace(\" \", \"%20\"))\n",
        "url += \"format=jsonv2\"\n",
        "\n",
        "# url\n",
        "x = requests.get(url, headers=agentheader)\n",
        "x\n",
        "content = x.json()\n",
        "content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbi-MK_aSews",
        "outputId": "df1ff8e9-5346-4765-9445-887f1f01c97b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# url = \"https://catfact.ninja/fact\"\n",
        "# r = requests.get(url)\n",
        "# r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2-ya91IIzk-"
      },
      "source": [
        "Great work! You were able to construct a function and tool that the LLM used to output the parameters necessary for a function call, then you actually made the function call to obtain the coordinates of the specified location.\n",
        "\n",
        "Here we used the [OpenStreetMap Nominatim API](https://nominatim.openstreetmap.org/ui/search.html) to geocode an address to make it easy to use and learn in this notebook. If you're working with large amounts of maps or geolocation data, you can use the [Google Maps Geocoding API](https://developers.google.com/maps/documentation/geocoding)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xpm8opEIzlJ"
      },
      "source": [
        "### Function calling in a chat session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBWHer6GIzlJ"
      },
      "source": [
        "In this example, you'll use the chat model in Gemini to help customers get information about products in a store.\n",
        "\n",
        "You'll start by defining multiple functions within a tool for getting product information, getting the location of stores, and placing an order:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD9wYRJrIzlJ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "get_product_info_func = FunctionDeclaration(\n",
        "    name=\"get_product_sku\",\n",
        "    description=\"Get the SKU for a product\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"product_name\": {\"type\": \"string\", \"description\": \"Product name\"}\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "get_store_location_func = FunctionDeclaration(\n",
        "    name=\"get_store_location\",\n",
        "    description=\"Get the location of the closest store\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"Location\"}},\n",
        "    },\n",
        ")\n",
        "\n",
        "place_order_func = FunctionDeclaration(\n",
        "    name=\"place_order\",\n",
        "    description=\"Place an order\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"product\": {\"type\": \"string\", \"description\": \"Product name\"},\n",
        "            \"address\": {\"type\": \"string\", \"description\": \"Shipping address\"},\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "retail_tool = Tool(\n",
        "    function_declarations=[\n",
        "        get_product_info_func,\n",
        "        get_store_location_func,\n",
        "        place_order_func,\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb2mBid9IzlJ"
      },
      "source": [
        "Note that you can also use function calling in a multi-turn chat session, and you can specify tools when creating a model to avoid having to send them with every request:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_iiI16EIzlJ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\n",
        "    \"gemini-1.0-pro\", generation_config={\"temperature\": 0}, tools=[retail_tool]\n",
        ")\n",
        "chat = model.start_chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfaYK5HeIzlJ"
      },
      "source": [
        "Great! Let's start the conversation by asking if they have a certain product in stock:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zfkBubDIzlJ",
        "outputId": "d1ab5019-ce9b-450e-a4be-631cb2885d19",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "function_call {\n",
              "  name: \"get_product_sku\"\n",
              "  args {\n",
              "    fields {\n",
              "      key: \"product_name\"\n",
              "      value {\n",
              "        string_value: \"Pixel 8 Pro\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Do you have the Pixel 8 Pro in stock?\n",
        "\"\"\"\n",
        "\n",
        "response = chat.send_message(prompt)\n",
        "response.candidates[0].content.parts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-5ncQ5yIzlJ"
      },
      "source": [
        "As expected, the response includes a structured function call that we can use to communicate with external systems.\n",
        "\n",
        "In reality, you would execute function calls against an external system or database. Since this notebook focuses on the ability to extract function parameter and generate function calls, you'll use mock data to feed responses back to the model rather that using an actual API server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj3MjONiIzlK",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# This is where you would make an API request to return the status of their order.\n",
        "# Use synthetic data to simulate a response payload from an external API.\n",
        "\n",
        "api_response = {\"sku\": \"GA04834-US\", \"in_stock\": \"yes\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5mW3PIHIzlK"
      },
      "source": [
        "Now, let's include details from the external API call and generate a response to the user:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nIXwLYxIzlK",
        "outputId": "3818d170-6fd8-482d-bc2a-54a9342b3cca",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text: \"Yes, we have the Pixel 8 Pro in stock. The SKU is GA04834-US.\""
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.send_message(\n",
        "    Part.from_function_response(\n",
        "        name=\"get_product_sku\",\n",
        "        response={\n",
        "            \"content\": api_response,\n",
        "        },\n",
        "    ),\n",
        ")\n",
        "response.candidates[0].content.parts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9iTcdipIzlK"
      },
      "source": [
        "Next, the user might ask where they can buy a phone from a nearby store:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUiIGHaEIzlK",
        "outputId": "1d577e2e-d633-44d6-d6b9-89e8458b9b7b",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "function_call {\n",
              "  name: \"get_store_location\"\n",
              "  args {\n",
              "    fields {\n",
              "      key: \"location\"\n",
              "      value {\n",
              "        string_value: \"Mountain View, CA\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Is there a store in Mountain View, CA that I can visit to try it out?\n",
        "\"\"\"\n",
        "\n",
        "response = chat.send_message(prompt)\n",
        "response.candidates[0].content.parts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tblU99nrIzlK"
      },
      "source": [
        "We get a response with another structured function call, this time it's set up to use a different function from our tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP8R7r9bIzlK",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# This is where you would make an API request to get the location of the store closest to the user.\n",
        "# Use synthetic data to simulate a response payload from an external API.\n",
        "\n",
        "api_response = {\"store\": \"2000 N Shoreline Blvd, Mountain View, CA 94043, US\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-dB52srIzlK"
      },
      "source": [
        "Again, let's include details from the external API call and generate a response to the user:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IOn2rfYIzlK",
        "outputId": "fbe30f1b-60ac-44a4-9f29-e1452fd50cc5",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text: \"Yes, there is a store in Mountain View, CA that you can visit to try out the Pixel 8 Pro. The address is 2000 N Shoreline Blvd, Mountain View, CA 94043, US.\""
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.send_message(\n",
        "    Part.from_function_response(\n",
        "        name=\"get_store_location\",\n",
        "        response={\n",
        "            \"content\": api_response,\n",
        "        },\n",
        "    ),\n",
        ")\n",
        "response.candidates[0].content.parts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPDZ-YufIzlK"
      },
      "source": [
        "Finally, the user might ask to order a phone and have it shipped to an address:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7DZsPuMIzlK",
        "outputId": "eb0f3807-0bc1-4fff-d5a1-945e7351503c",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "function_call {\n",
              "  name: \"place_order\"\n",
              "  args {\n",
              "    fields {\n",
              "      key: \"address\"\n",
              "      value {\n",
              "        string_value: \"1155 Borregas Ave, Sunnyvale, CA 94089\"\n",
              "      }\n",
              "    }\n",
              "    fields {\n",
              "      key: \"product\"\n",
              "      value {\n",
              "        string_value: \"Pixel 8 Pro\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "I'd like to order a Pixel 8 Pro and have it shipped to 1155 Borregas Ave, Sunnyvale, CA 94089.\n",
        "\"\"\"\n",
        "\n",
        "response = chat.send_message(prompt)\n",
        "response.candidates[0].content.parts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVRU8sA-IzlK"
      },
      "source": [
        "Perfect! We extracted the user's desired product and address, and now we can call an API to place the order:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psAihw23IzlK",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# This is where you would make an API request to return the status of their order.\n",
        "# Use synthetic data to simulate a response payload from an external API.\n",
        "\n",
        "api_response = {\n",
        "    \"payment_status\": \"paid\",\n",
        "    \"order_number\": 12345,\n",
        "    \"est_arrival\": \"2 days\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0knZ2efIzlL"
      },
      "source": [
        "As before, let's include details from the external API call and generate a response to the user:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqHghg3oIzlL",
        "outputId": "40ef57c1-2b7a-4ce2-f8da-6dbcc7ff2349",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text: \"OK. I have placed an order for a Pixel 8 Pro and it will be shipped to 1155 Borregas Ave, Sunnyvale, CA 94089. Your order number is 12345. The estimated arrival time is 2 days.\""
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.send_message(\n",
        "    Part.from_function_response(\n",
        "        name=\"place_order\",\n",
        "        response={\n",
        "            \"content\": api_response,\n",
        "        },\n",
        "    ),\n",
        ")\n",
        "response.candidates[0].content.parts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2oglYmCIzlL"
      },
      "source": [
        "And you're done! You successfully had a multi-turn conversation with Gemini, generated function calls, handled passing (mock) data back to the model, and generated messages that made use of the function responses."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "conda-root-py",
      "name": "workbench-notebooks.m115",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
